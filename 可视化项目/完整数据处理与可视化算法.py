#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ½å–å¼å¸é™„æ›²çº¿å®Œæ•´æ•°æ®å¤„ç†ä¸å¯è§†åŒ–ç®—æ³•
åŸºäº7.24æ•°æ®.csvï¼Œå®ç°ä»æ•°æ®æ¸…æ´—åˆ°å¯è§†åŒ–çš„å…¨æµç¨‹
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from scipy import stats
from scipy.optimize import curve_fit
from typing import List, Dict, Tuple, Optional
from enum import Enum
from dataclasses import dataclass
import warnings
import os
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

class WarningLevel(Enum):
    """é¢„è­¦ç­‰çº§"""
    GREEN = "ç»¿è‰²"      # æ— éœ€æ›´æ¢
    YELLOW = "é»„è‰²"     # é€‚æ—¶æ›´æ¢
    ORANGE = "æ©™è‰²"     # ç«‹å³æ›´æ¢
    RED = "çº¢è‰²"        # ç«‹å³æ›´æ¢

@dataclass
class WarningEvent:
    """é¢„è­¦äº‹ä»¶"""
    timestamp: float
    warning_level: WarningLevel
    breakthrough_ratio: float  # ç©¿é€ç‡ %
    efficiency: float         # å¸é™„æ•ˆç‡ %
    reason: str              # é¢„è­¦åŸå› 
    recommendation: str      # å»ºè®®æªæ–½
    predicted_saturation_time: Optional[float] = None  # é¢„è®¡é¥±å’Œæ—¶é—´

class LogisticWarningModel:
    """åŸºäºLogisticæ¨¡å‹çš„é¢„è­¦ç³»ç»Ÿ"""

    def __init__(self,
                 breakthrough_start_threshold: float = 0.05,  # ç©¿é€èµ·å§‹ç‚¹é˜ˆå€¼ 5%
                 saturation_threshold: float = 0.95,         # é¥±å’Œç‚¹é˜ˆå€¼ 95%
                 warning_ratio: float = 0.8):                # é¢„è­¦ç‚¹æ¯”ä¾‹ 80%
        """
        åˆå§‹åŒ–é¢„è­¦æ¨¡å‹

        å‚æ•°:
            breakthrough_start_threshold: ç©¿é€èµ·å§‹ç‚¹é˜ˆå€¼
            saturation_threshold: é¥±å’Œç‚¹é˜ˆå€¼
            warning_ratio: é¢„è­¦ç‚¹æ¯”ä¾‹ï¼ˆä»ç©¿é€èµ·å§‹åˆ°é¥±å’Œçš„80%ï¼‰
        """
        self.breakthrough_start_threshold = breakthrough_start_threshold
        self.saturation_threshold = saturation_threshold
        self.warning_ratio = warning_ratio

        self.params = None
        self.fitted = False
        self.breakthrough_start_time = None
        self.predicted_saturation_time = None
        self.warning_time = None

    @staticmethod
    def logistic_function(t, A, k, t0):
        """
        Logisticå‡½æ•°: C/C0 = A / (1 + exp(-k*(t-t0)))

        å‚æ•°:
            t: æ—¶é—´
            A: æœ€å¤§ç©¿é€ç‡ï¼ˆé€šå¸¸æ¥è¿‘1ï¼‰
            k: å¢é•¿ç‡
            t0: æ‹ç‚¹æ—¶é—´
        """
        return A / (1 + np.exp(-k * (t - t0)))

    def fit_model(self, time_data: np.array, efficiency_data: np.array) -> bool:
        """
        æ‹ŸåˆLogisticæ¨¡å‹

        å‚æ•°:
            time_data: æ—¶é—´æ•°æ®
            efficiency_data: å¸é™„æ•ˆç‡æ•°æ®

        è¿”å›:
            æ˜¯å¦æ‹ŸåˆæˆåŠŸ
        """
        try:
            # å°†æ•ˆç‡è½¬æ¢ä¸ºç©¿é€ç‡
            breakthrough_data = (100 - efficiency_data) / 100
            breakthrough_data = np.clip(breakthrough_data, 0.001, 0.999)

            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
            valid_mask = (breakthrough_data > 0) & (breakthrough_data < 1) & (time_data > 0)
            if np.sum(valid_mask) < 5:  # è‡³å°‘éœ€è¦5ä¸ªæ•°æ®ç‚¹
                print("æ•°æ®ç‚¹ä¸è¶³ï¼Œæ— æ³•æ‹ŸåˆLogisticæ¨¡å‹")
                return False

            t_valid = time_data[valid_mask]
            bt_valid = breakthrough_data[valid_mask]

            # åˆå§‹å‚æ•°ä¼°è®¡
            A_init = 0.95  # æœ€å¤§ç©¿é€ç‡
            k_init = 0.0001  # å¢é•¿ç‡
            t0_init = np.median(t_valid)  # æ‹ç‚¹æ—¶é—´

            # æ‹Ÿåˆ
            self.params, _ = curve_fit(
                self.logistic_function,
                t_valid, bt_valid,
                p0=[A_init, k_init, t0_init],
                bounds=([0.5, 0.00001, 0], [1.0, 0.01, np.max(t_valid)*2]),
                maxfev=3000
            )

            self.fitted = True

            # è®¡ç®—å…³é”®æ—¶é—´ç‚¹
            self._calculate_key_timepoints(t_valid)

            print(f"Logisticæ¨¡å‹æ‹ŸåˆæˆåŠŸ: A={self.params[0]:.3f}, k={self.params[1]:.6f}, t0={self.params[2]:.1f}")
            return True

        except Exception as e:
            print(f"Logisticæ¨¡å‹æ‹Ÿåˆå¤±è´¥: {e}")
            return False

    def _calculate_key_timepoints(self, time_data: np.array):
        """è®¡ç®—å…³é”®æ—¶é—´ç‚¹"""
        if not self.fitted:
            return

        A, k, t0 = self.params

        # è®¡ç®—ç©¿é€èµ·å§‹æ—¶é—´ï¼ˆ5%ç©¿é€ç‡ï¼‰
        try:
            if A > self.breakthrough_start_threshold:
                self.breakthrough_start_time = t0 - np.log(A / self.breakthrough_start_threshold - 1) / k
                if self.breakthrough_start_time < 0:
                    self.breakthrough_start_time = np.min(time_data)
            else:
                self.breakthrough_start_time = np.min(time_data)
        except:
            self.breakthrough_start_time = np.min(time_data)

        # è®¡ç®—é¥±å’Œæ—¶é—´ï¼ˆ95%ç©¿é€ç‡ï¼‰
        try:
            if A > self.saturation_threshold:
                self.predicted_saturation_time = t0 - np.log(A / self.saturation_threshold - 1) / k
            else:
                # å¦‚æœæ¨¡å‹é¢„æµ‹çš„æœ€å¤§ç©¿é€ç‡å°äº95%ï¼Œåˆ™ä½¿ç”¨å¤–æ¨
                self.predicted_saturation_time = np.max(time_data) * 1.5
        except:
            self.predicted_saturation_time = np.max(time_data) * 1.5

        # è®¡ç®—é¢„è­¦æ—¶é—´ï¼ˆç©¿é€èµ·å§‹åˆ°é¥±å’Œçš„80%ï¼‰
        if self.breakthrough_start_time is not None and self.predicted_saturation_time is not None:
            time_span = self.predicted_saturation_time - self.breakthrough_start_time
            self.warning_time = self.breakthrough_start_time + time_span * self.warning_ratio

        print(f"å…³é”®æ—¶é—´ç‚¹è®¡ç®—:")
        print(f"  ç©¿é€èµ·å§‹æ—¶é—´: {self.breakthrough_start_time:.1f}s")
        print(f"  é¢„è­¦æ—¶é—´: {self.warning_time:.1f}s")
        print(f"  é¢„æµ‹é¥±å’Œæ—¶é—´: {self.predicted_saturation_time:.1f}s")

    def predict_breakthrough(self, time_points: np.array) -> np.array:
        """é¢„æµ‹æŒ‡å®šæ—¶é—´ç‚¹çš„ç©¿é€ç‡"""
        if not self.fitted:
            return np.zeros_like(time_points)

        return self.logistic_function(time_points, *self.params)

    def get_warning_level(self, current_time: float, current_efficiency: float) -> WarningLevel:
        """
        æ ¹æ®å½“å‰æ—¶é—´å’Œæ•ˆç‡ç¡®å®šé¢„è­¦ç­‰çº§

        å‚æ•°:
            current_time: å½“å‰æ—¶é—´
            current_efficiency: å½“å‰å¸é™„æ•ˆç‡

        è¿”å›:
            é¢„è­¦ç­‰çº§
        """
        current_breakthrough = (100 - current_efficiency) / 100

        # åŸºäºç©¿é€ç‡çš„é¢„è­¦
        if current_breakthrough <= self.breakthrough_start_threshold:
            return WarningLevel.GREEN
        elif current_breakthrough >= self.saturation_threshold:
            return WarningLevel.RED

        # åŸºäºæ—¶é—´çš„é¢„è­¦ï¼ˆå¦‚æœæ¨¡å‹å·²æ‹Ÿåˆï¼‰
        if self.fitted and self.warning_time is not None and self.predicted_saturation_time is not None:
            if current_time >= self.predicted_saturation_time:
                return WarningLevel.RED
            elif current_time >= self.warning_time:
                return WarningLevel.ORANGE
            elif current_breakthrough > self.breakthrough_start_threshold:
                return WarningLevel.YELLOW

        # ä»…åŸºäºç©¿é€ç‡çš„é¢„è­¦
        if current_breakthrough > 0.8:  # 80%ç©¿é€ç‡
            return WarningLevel.ORANGE
        elif current_breakthrough > self.breakthrough_start_threshold:
            return WarningLevel.YELLOW

        return WarningLevel.GREEN

    def generate_warning_event(self, current_time: float, current_efficiency: float) -> Optional[WarningEvent]:
        """ç”Ÿæˆé¢„è­¦äº‹ä»¶"""
        level = self.get_warning_level(current_time, current_efficiency)

        if level == WarningLevel.GREEN:
            return None

        current_breakthrough = (100 - current_efficiency) / 100

        # ç”Ÿæˆé¢„è­¦åŸå› å’Œå»ºè®®
        if level == WarningLevel.YELLOW:
            reason = f"ç©¿é€ç‡è¾¾åˆ°{current_breakthrough*100:.1f}%ï¼Œå·²è¶…è¿‡èµ·å§‹ç‚¹é˜ˆå€¼"
            recommendation = "å»ºè®®å¼€å§‹å‡†å¤‡æ›´æ¢æ´»æ€§ç‚­ï¼Œç›‘æ§ç©¿é€ç‡å˜åŒ–è¶‹åŠ¿"
        elif level == WarningLevel.ORANGE:
            if self.warning_time and current_time >= self.warning_time:
                reason = f"å·²è¾¾åˆ°é¢„è­¦æ—¶é—´ç‚¹({self.warning_time:.1f}s)ï¼Œç©¿é€ç‡{current_breakthrough*100:.1f}%"
            else:
                reason = f"ç©¿é€ç‡è¾¾åˆ°{current_breakthrough*100:.1f}%ï¼Œæ¥è¿‘é¥±å’ŒçŠ¶æ€"
            recommendation = "ç«‹å³å®‰æ’æ›´æ¢æ´»æ€§ç‚­ï¼Œè®¾å¤‡å¤„äºéç¨³å®šè¿è¡ŒçŠ¶æ€"
        else:  # RED
            if self.predicted_saturation_time and current_time >= self.predicted_saturation_time:
                reason = f"å·²è¾¾åˆ°é¢„æµ‹é¥±å’Œæ—¶é—´({self.predicted_saturation_time:.1f}s)"
            else:
                reason = f"ç©¿é€ç‡è¾¾åˆ°{current_breakthrough*100:.1f}%ï¼Œæ´»æ€§ç‚­å·²é¥±å’Œ"
            recommendation = "ç´§æ€¥æ›´æ¢æ´»æ€§ç‚­ï¼è®¾å¤‡å·²æ— æ³•æ­£å¸¸å‡€åŒ–VOCs"

        return WarningEvent(
            timestamp=current_time,
            warning_level=level,
            breakthrough_ratio=current_breakthrough * 100,
            efficiency=current_efficiency,
            reason=reason,
            recommendation=recommendation,
            predicted_saturation_time=self.predicted_saturation_time
        )

class AdsorptionCurveProcessor:
    """æŠ½å–å¼å¸é™„æ›²çº¿å®Œæ•´å¤„ç†å™¨"""
    
    def __init__(self, data_file: str):
        self.data_file = data_file
        # æå–åŸå§‹æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        self.base_filename = os.path.splitext(os.path.basename(data_file))[0]
        self.raw_data = None
        self.cleaned_data_ks = None
        self.cleaned_data_boxplot = None
        self.efficiency_data_ks = None
        self.efficiency_data_boxplot = None

        # é¢„è­¦ç³»ç»Ÿ
        self.warning_model = LogisticWarningModel()
        self.warning_events = []
        
    def load_data(self) -> bool:
        """åŠ è½½åŸå§‹æ•°æ® - æ”¯æŒCSVã€XLSXã€XLSæ ¼å¼"""
        try:
            print("=== åŠ è½½åŸå§‹æ•°æ® ===")

            # è·å–æ–‡ä»¶æ‰©å±•å
            file_extension = os.path.splitext(self.data_file)[1].lower()
            print(f"æ£€æµ‹åˆ°æ–‡ä»¶æ ¼å¼: {file_extension}")

            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©ç›¸åº”çš„è¯»å–æ–¹æ³•
            if file_extension == '.csv':
                self.raw_data = pd.read_csv(self.data_file, encoding='utf-8-sig')
                print("ä½¿ç”¨CSVæ ¼å¼åŠ è½½æ•°æ®")
            elif file_extension in ['.xlsx', '.xls']:
                # å°è¯•è¯»å–Excelæ–‡ä»¶ï¼Œé»˜è®¤è¯»å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
                self.raw_data = pd.read_excel(self.data_file, engine='openpyxl' if file_extension == '.xlsx' else 'xlrd')
                print(f"ä½¿ç”¨Excelæ ¼å¼åŠ è½½æ•°æ® (å¼•æ“: {'openpyxl' if file_extension == '.xlsx' else 'xlrd'})")
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}ã€‚æ”¯æŒçš„æ ¼å¼: .csv, .xlsx, .xls")

            # è½¬æ¢æ—¶é—´åˆ—
            if 'åˆ›å»ºæ—¶é—´' in self.raw_data.columns:
                self.raw_data['åˆ›å»ºæ—¶é—´'] = pd.to_datetime(self.raw_data['åˆ›å»ºæ—¶é—´'])
                print(f"åŸå§‹æ•°æ®åŠ è½½æˆåŠŸ: {len(self.raw_data)} æ¡è®°å½•")
                print(f"æ—¶é—´èŒƒå›´: {self.raw_data['åˆ›å»ºæ—¶é—´'].min()} åˆ° {self.raw_data['åˆ›å»ºæ—¶é—´'].max()}")
            else:
                print(f"åŸå§‹æ•°æ®åŠ è½½æˆåŠŸ: {len(self.raw_data)} æ¡è®°å½•")
                print("è­¦å‘Š: æœªæ‰¾åˆ°'åˆ›å»ºæ—¶é—´'åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
                # æ˜¾ç¤ºå‰å‡ åˆ—çš„åˆ—åä»¥ä¾¿è°ƒè¯•
                print(f"æ•°æ®åˆ—å: {list(self.raw_data.columns[:10])}")

            return True

        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            print(f"è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®")
            if file_extension in ['.xlsx', '.xls']:
                print("æç¤º: Excelæ–‡ä»¶éœ€è¦å®‰è£…openpyxlæˆ–xlrdåº“")
                print("å®‰è£…å‘½ä»¤: pip install openpyxl xlrd")
            return False
    
    def basic_data_cleaning(self, data: pd.DataFrame) -> pd.DataFrame:
        """åŸºç¡€æ•°æ®æ¸…æ´—"""
        print("\n=== åŸºç¡€æ•°æ®æ¸…æ´— ===")
        original_count = len(data)
        
        # 1. è·å–å·¥ä½œçŠ¶æ€æ•°æ®ï¼ˆé£é€Ÿå€¼å¤§äº0.5ï¼‰
        data = data[data['é£ç®¡å†…é£é€Ÿå€¼'] > 0.5].copy()
        print(f"1. ä¿ç•™é£é€Ÿ>0.5çš„æ•°æ®: {len(data)} æ¡ (å‰”é™¤ {original_count - len(data)} æ¡)")
        
        # 2. æ ¹æ®è¿›å£0å‡ºå£1åˆ—åˆ†åˆ«å‰”é™¤0å€¼
        before_zero_removal = len(data)
        # å½“è¿›å£0å‡ºå£1=0æ—¶ï¼Œå‰”é™¤è¿›å£vocä¸º0çš„è®°å½•
        # å½“è¿›å£0å‡ºå£1=1æ—¶ï¼Œå‰”é™¤å‡ºå£vocä¸º0çš„è®°å½•
        inlet_mask = (data['è¿›å£0å‡ºå£1'] == 0) & (data['è¿›å£voc'] > 0)
        outlet_mask = (data['è¿›å£0å‡ºå£1'] == 1) & (data['å‡ºå£voc'] > 0)
        data = data[inlet_mask | outlet_mask].copy()
        print(f"2. æ ¹æ®è¿›å£0å‡ºå£1åˆ—åˆ†åˆ«å‰”é™¤ç›¸åº”VOCä¸º0çš„æ•°æ®: {len(data)} æ¡ (å‰”é™¤ {before_zero_removal - len(data)} æ¡)")
        
        # 3. å‰”é™¤é£é‡=0çš„æ•°æ®
        before_flow_removal = len(data)
        data = data[data['é£é‡'] > 0].copy()
        print(f"3. å‰”é™¤é£é‡=0çš„æ•°æ®: {len(data)} æ¡ (å‰”é™¤ {before_flow_removal - len(data)} æ¡)")

        # 4. å‰”é™¤å‡ºå£æµ“åº¦å¤§äºç­‰äºè¿›å£æµ“åº¦çš„è®°å½•
        before_concentration_removal = len(data)
        data = self._remove_invalid_concentration_pairs(data)
        print(f"4. å‰”é™¤å‡ºå£æµ“åº¦â‰¥è¿›å£æµ“åº¦çš„è®°å½•: {len(data)} æ¡ (å‰”é™¤ {before_concentration_removal - len(data)} æ¡)")

        return data

    def _remove_invalid_concentration_pairs(self, data: pd.DataFrame) -> pd.DataFrame:
        """å‰”é™¤å‡ºå£æµ“åº¦å¤§äºç­‰äºè¿›å£æµ“åº¦çš„è®°å½•"""
        print("   æ­£åœ¨æ£€æŸ¥è¿›å‡ºå£æµ“åº¦é…å¯¹...")

        # åˆ†ç¦»è¿›å£å’Œå‡ºå£æ•°æ®
        inlet_data = data[data['è¿›å£0å‡ºå£1'] == 0].copy()
        outlet_data = data[data['è¿›å£0å‡ºå£1'] == 1].copy()

        if len(inlet_data) == 0 or len(outlet_data) == 0:
            print("   è­¦å‘Š: ç¼ºå°‘è¿›å£æˆ–å‡ºå£æ•°æ®ï¼Œè·³è¿‡æµ“åº¦é…å¯¹æ£€æŸ¥")
            return data

        # æŒ‰æ—¶é—´æ’åº
        inlet_data = inlet_data.sort_values('åˆ›å»ºæ—¶é—´')
        outlet_data = outlet_data.sort_values('åˆ›å»ºæ—¶é—´')

        # ä½¿ç”¨æ—¶é—´çª—å£åŒ¹é…è¿›å‡ºå£æ•°æ®
        valid_records = []
        time_window = pd.Timedelta(minutes=30)  # 30åˆ†é’Ÿæ—¶é—´çª—å£

        removed_count = 0

        # æ£€æŸ¥æ¯ä¸ªè¿›å£è®°å½•
        for _, inlet_record in inlet_data.iterrows():
            inlet_time = inlet_record['åˆ›å»ºæ—¶é—´']
            inlet_voc = inlet_record['è¿›å£voc']

            # æ‰¾åˆ°æ—¶é—´çª—å£å†…çš„å‡ºå£è®°å½•
            outlet_candidates = outlet_data[
                (outlet_data['åˆ›å»ºæ—¶é—´'] >= inlet_time - time_window) &
                (outlet_data['åˆ›å»ºæ—¶é—´'] <= inlet_time + time_window)
            ]

            if len(outlet_candidates) > 0:
                # æ‰¾åˆ°æœ€è¿‘çš„å‡ºå£è®°å½•
                time_diffs = abs(outlet_candidates['åˆ›å»ºæ—¶é—´'] - inlet_time)
                closest_outlet = outlet_candidates.loc[time_diffs.idxmin()]
                outlet_voc = closest_outlet['å‡ºå£voc']

                # æ£€æŸ¥æµ“åº¦å…³ç³»ï¼šåªä¿ç•™è¿›å£æµ“åº¦ >= å‡ºå£æµ“åº¦çš„è®°å½•
                if inlet_voc >= outlet_voc:
                    valid_records.append(inlet_record)
                    # åŒæ—¶ä¿ç•™å¯¹åº”çš„å‡ºå£è®°å½•
                    valid_records.append(closest_outlet)
                else:
                    removed_count += 2  # è¿›å£å’Œå‡ºå£è®°å½•éƒ½è¢«å‰”é™¤
            else:
                # æ²¡æœ‰åŒ¹é…çš„å‡ºå£è®°å½•ï¼Œä¿ç•™è¿›å£è®°å½•
                valid_records.append(inlet_record)

        # æ£€æŸ¥å‰©ä½™çš„å‡ºå£è®°å½•ï¼ˆæ²¡æœ‰åŒ¹é…è¿›å£è®°å½•çš„ï¼‰
        for _, outlet_record in outlet_data.iterrows():
            outlet_time = outlet_record['åˆ›å»ºæ—¶é—´']

            # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨valid_recordsä¸­
            already_included = any(
                record['åˆ›å»ºæ—¶é—´'] == outlet_time and record['è¿›å£0å‡ºå£1'] == 1
                for record in valid_records
            )

            if not already_included:
                # æ‰¾åˆ°æ—¶é—´çª—å£å†…çš„è¿›å£è®°å½•
                inlet_candidates = inlet_data[
                    (inlet_data['åˆ›å»ºæ—¶é—´'] >= outlet_time - time_window) &
                    (inlet_data['åˆ›å»ºæ—¶é—´'] <= outlet_time + time_window)
                ]

                if len(inlet_candidates) == 0:
                    # æ²¡æœ‰åŒ¹é…çš„è¿›å£è®°å½•ï¼Œä¿ç•™å‡ºå£è®°å½•
                    valid_records.append(outlet_record)

        if valid_records:
            result_data = pd.DataFrame(valid_records).drop_duplicates()
            print(f"   æµ“åº¦é…å¯¹æ£€æŸ¥å®Œæˆï¼Œå‰”é™¤äº† {removed_count} æ¡è®°å½•")
            print(f"   å‰”é™¤åŸå› ï¼šå‡ºå£æµ“åº¦ â‰¥ è¿›å£æµ“åº¦")
            return result_data
        else:
            print("   è­¦å‘Š: æµ“åº¦é…å¯¹æ£€æŸ¥åæ— æœ‰æ•ˆæ•°æ®")
            return pd.DataFrame()

    def ks_test_cleaning(self, data: pd.DataFrame) -> pd.DataFrame:
        """K-Sæ£€éªŒæ•°æ®æ¸…æ´—"""
        print("\n=== K-Sæ£€éªŒæ•°æ®æ¸…æ´— ===")
        
        # åˆ†åˆ«å¤„ç†è¿›å£å’Œå‡ºå£æ•°æ®
        inlet_data = data[data['è¿›å£0å‡ºå£1'] == 0].copy()
        outlet_data = data[data['è¿›å£0å‡ºå£1'] == 1].copy()
        
        cleaned_data = []
        
        for data_type, subset in [('è¿›å£', inlet_data), ('å‡ºå£', outlet_data)]:
            if len(subset) == 0:
                continue
                
            voc_column = 'è¿›å£voc' if data_type == 'è¿›å£' else 'å‡ºå£voc'
            voc_values = subset[voc_column].dropna()
            
            if len(voc_values) < 10:  # æ•°æ®é‡å¤ªå°‘ï¼Œè·³è¿‡æ£€éªŒ
                cleaned_data.append(subset)
                print(f"{data_type}æ•°æ®é‡å¤ªå°‘({len(voc_values)}æ¡)ï¼Œè·³è¿‡K-Sæ£€éªŒ")
                continue
            
            # K-Sæ£€éªŒæ­£æ€æ€§
            _, p_value = stats.kstest(voc_values, 'norm', args=(voc_values.mean(), voc_values.std()))
            print(f"{data_type}æ•°æ®K-Sæ£€éªŒ på€¼: {p_value:.4f}")
            
            if p_value > 0.05:
                # æ­£æ€åˆ†å¸ƒï¼Œä½¿ç”¨3Ïƒå‡†åˆ™
                mean_val = voc_values.mean()
                std_val = voc_values.std()
                threshold = 3 * std_val
                
                mask = np.abs(voc_values - mean_val) <= threshold
                cleaned_subset = subset[mask]
                removed_count = len(subset) - len(cleaned_subset)
                print(f"{data_type}æ•°æ®æ­£æ€åˆ†å¸ƒï¼Œä½¿ç”¨3Ïƒå‡†åˆ™: ä¿ç•™{len(cleaned_subset)}æ¡ï¼Œå‰”é™¤{removed_count}æ¡")
                
            else:
                # éæ­£æ€åˆ†å¸ƒï¼Œä½¿ç”¨Z-score
                z_scores = np.abs(stats.zscore(voc_values))
                mask = z_scores <= 3
                cleaned_subset = subset[mask]
                removed_count = len(subset) - len(cleaned_subset)
                print(f"{data_type}æ•°æ®éæ­£æ€åˆ†å¸ƒï¼Œä½¿ç”¨Z-score: ä¿ç•™{len(cleaned_subset)}æ¡ï¼Œå‰”é™¤{removed_count}æ¡")
            
            cleaned_data.append(cleaned_subset)
        
        # åˆå¹¶æ¸…æ´—åçš„æ•°æ®
        if cleaned_data:
            result = pd.concat(cleaned_data, ignore_index=True)
            result = result.sort_values('åˆ›å»ºæ—¶é—´').reset_index(drop=True)
            print(f"K-Sæ£€éªŒæ¸…æ´—å®Œæˆ: æœ€ç»ˆä¿ç•™ {len(result)} æ¡è®°å½•")
            return result
        else:
            return pd.DataFrame()
    
    def boxplot_cleaning(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç®±å‹å›¾å¼‚å¸¸å€¼æ¸…æ´—"""
        print("\n=== ç®±å‹å›¾å¼‚å¸¸å€¼æ¸…æ´— ===")
        
        # åˆ†åˆ«å¤„ç†è¿›å£å’Œå‡ºå£æ•°æ®
        inlet_data = data[data['è¿›å£0å‡ºå£1'] == 0].copy()
        outlet_data = data[data['è¿›å£0å‡ºå£1'] == 1].copy()
        
        cleaned_data = []
        
        for data_type, subset in [('è¿›å£', inlet_data), ('å‡ºå£', outlet_data)]:
            if len(subset) == 0:
                continue
                
            voc_column = 'è¿›å£voc' if data_type == 'è¿›å£' else 'å‡ºå£voc'
            voc_values = subset[voc_column].dropna()
            
            if len(voc_values) < 4:  # æ•°æ®é‡å¤ªå°‘ï¼Œè·³è¿‡æ¸…æ´—
                cleaned_data.append(subset)
                print(f"{data_type}æ•°æ®é‡å¤ªå°‘({len(voc_values)}æ¡)ï¼Œè·³è¿‡ç®±å‹å›¾æ¸…æ´—")
                continue
            
            # è®¡ç®—å››åˆ†ä½æ•°
            Q1 = voc_values.quantile(0.25)
            Q3 = voc_values.quantile(0.75)
            IQR = Q3 - Q1
            
            # è®¡ç®—å¼‚å¸¸å€¼è¾¹ç•Œ
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            # è¿‡æ»¤å¼‚å¸¸å€¼
            mask = (voc_values >= lower_bound) & (voc_values <= upper_bound)
            cleaned_subset = subset[mask]
            removed_count = len(subset) - len(cleaned_subset)
            
            print(f"{data_type}æ•°æ®ç®±å‹å›¾æ¸…æ´—: Q1={Q1:.2f}, Q3={Q3:.2f}, IQR={IQR:.2f}")
            print(f"  è¾¹ç•Œ: [{lower_bound:.2f}, {upper_bound:.2f}], ä¿ç•™{len(cleaned_subset)}æ¡ï¼Œå‰”é™¤{removed_count}æ¡")
            
            cleaned_data.append(cleaned_subset)
        
        # åˆå¹¶æ¸…æ´—åçš„æ•°æ®
        if cleaned_data:
            result = pd.concat(cleaned_data, ignore_index=True)
            result = result.sort_values('åˆ›å»ºæ—¶é—´').reset_index(drop=True)
            print(f"ç®±å‹å›¾æ¸…æ´—å®Œæˆ: æœ€ç»ˆä¿ç•™ {len(result)} æ¡è®°å½•")
            return result
        else:
            return pd.DataFrame()
    
    def calculate_efficiency_data(self, data: pd.DataFrame, method_name: str) -> Optional[pd.DataFrame]:
        """è®¡ç®—å¸é™„æ•ˆç‡æ•°æ®"""
        print(f"\n=== è®¡ç®—{method_name}å¸é™„æ•ˆç‡ ===")
        
        if len(data) == 0:
            print(f"è­¦å‘Š: {method_name}æ•°æ®ä¸ºç©º")
            return None
        
        # åˆ†ç¦»è¿›å‡ºå£æ•°æ®
        inlet_data = data[data['è¿›å£0å‡ºå£1'] == 0].copy()
        outlet_data = data[data['è¿›å£0å‡ºå£1'] == 1].copy()
        
        print(f"è¿›å£æ•°æ®: {len(inlet_data)} æ¡")
        print(f"å‡ºå£æ•°æ®: {len(outlet_data)} æ¡")
        
        if len(inlet_data) == 0 or len(outlet_data) == 0:
            print(f"è­¦å‘Š: {method_name}ç¼ºå°‘è¿›å£æˆ–å‡ºå£æ•°æ®")
            return None
        
        # æŒ‰æ—¶é—´æ’åº
        inlet_data = inlet_data.sort_values('åˆ›å»ºæ—¶é—´')
        outlet_data = outlet_data.sort_values('åˆ›å»ºæ—¶é—´')
        
        # è®¡ç®—æ•ˆç‡æ•°æ®
        efficiency_records = []
        
        # è·å–æ‰€æœ‰æ—¶é—´ç‚¹å¹¶æ’åº
        all_times = sorted(data['åˆ›å»ºæ—¶é—´'].unique())
        
        # è¯†åˆ«è¿ç»­çš„æ—¶é—´æ®µï¼ˆé—´éš”è¶…è¿‡1å°æ—¶è®¤ä¸ºæ˜¯ä¸åŒæ—¶é—´æ®µï¼‰
        time_segments = []
        current_segment = [all_times[0]]
        
        for i in range(1, len(all_times)):
            time_diff = (all_times[i] - all_times[i-1]).total_seconds() / 60
            if time_diff > 60:  # é—´éš”è¶…è¿‡1å°æ—¶
                time_segments.append(current_segment)
                current_segment = [all_times[i]]
            else:
                current_segment.append(all_times[i])
        
        if current_segment:
            time_segments.append(current_segment)
        
        print(f"è¯†åˆ«åˆ° {len(time_segments)} ä¸ªæ—¶é—´æ®µ")
        
        # ä¸ºæ¯ä¸ªæ—¶é—´æ®µè®¡ç®—æ•ˆç‡
        start_time = data['åˆ›å»ºæ—¶é—´'].min()
        
        for segment_idx, time_segment in enumerate(time_segments):
            segment_start = time_segment[0]
            segment_end = time_segment[-1]
            
            # è·å–è¯¥æ—¶é—´æ®µçš„æ•°æ®
            segment_data = data[
                (data['åˆ›å»ºæ—¶é—´'] >= segment_start) & 
                (data['åˆ›å»ºæ—¶é—´'] <= segment_end)
            ]
            
            segment_inlet = segment_data[segment_data['è¿›å£0å‡ºå£1'] == 0]
            segment_outlet = segment_data[segment_data['è¿›å£0å‡ºå£1'] == 1]
            
            if len(segment_inlet) > 0 and len(segment_outlet) > 0:
                # è®¡ç®—å¹³å‡æµ“åº¦
                avg_inlet = segment_inlet['è¿›å£voc'].mean()
                avg_outlet = segment_outlet['å‡ºå£voc'].mean()
                
                # æ ¹æ®ç®—æ³•è¦æ±‚è®¡ç®—æ•ˆç‡
                if avg_inlet > avg_outlet:  # C0 > C1
                    efficiency = (avg_outlet / avg_inlet) * 100
                else:  # C0 < C1ï¼Œä½¿ç”¨ä¸Šä¸€ä¸ªå°äºC1çš„C0
                    # ç®€åŒ–å¤„ç†ï¼šå¦‚æœè¿›å£æµ“åº¦å°äºå‡ºå£æµ“åº¦ï¼Œæ•ˆç‡è®¾ä¸º0
                    efficiency = 0.0
                
                
                # è®¡ç®—æ—¶é—´åæ ‡
                segment_mid_time = segment_start + (segment_end - segment_start) / 2
                time_minutes = (segment_mid_time - start_time).total_seconds() / 60
                
                efficiency_records.append({
                    'time': time_minutes,
                    'efficiency': efficiency,
                    'inlet_conc': avg_inlet,
                    'outlet_conc': avg_outlet,
                    'data_count': len(segment_data),
                    'window_start': segment_start,
                    'window_end': segment_end,
                    'segment_idx': segment_idx + 1
                })
                
                print(f"æ—¶æ®µ{segment_idx+1}: è¿›å£={avg_inlet:.2f}, å‡ºå£={avg_outlet:.2f}, æ•ˆç‡={efficiency:.1f}%")
        
        if efficiency_records:
            efficiency_df = pd.DataFrame(efficiency_records)
            print(f"ç”Ÿæˆæ•ˆç‡æ•°æ®: {len(efficiency_df)} ä¸ªæ—¶é—´æ®µ")
            print(f"å¹³å‡æ•ˆç‡: {efficiency_df['efficiency'].mean():.2f}%")
            return efficiency_df
        else:
            print(f"æ— æ³•ç”Ÿæˆ{method_name}æ•ˆç‡æ•°æ®")
            return None

    def _create_time_segments(self, efficiency_data: pd.DataFrame, time_intervals: int = None) -> List[Dict]:
        """åˆ›å»ºæ—¶é—´æ®µæ•°æ® - ä¸åŸºäºæœ€ç»ˆç‰ˆç®—æ³•çš„å¯è§†åŒ–ä¿æŒä¸€è‡´"""
        if len(efficiency_data) == 0:
            return []

        print(f"   åŸå§‹æ•ˆç‡æ•°æ®ç‚¹æ•°: {len(efficiency_data)}")

        # æŒ‰æ—¶é—´æ’åº
        efficiency_data_sorted = efficiency_data.sort_values('time').reset_index(drop=True)

        # å°†æ•°æ®åˆ†æˆ16ç»„ï¼Œç”¨äºæ ‡è®°å¤§æ—¶é—´æ®µï¼Œä½†ä¸èƒ½è¶…è¿‡æ•°æ®ç‚¹æ•°é‡
        target_groups = min(16, len(efficiency_data_sorted))
        group_size = max(1, len(efficiency_data_sorted) // target_groups)

        print(f"   å°† {len(efficiency_data_sorted)} ä¸ªæ—¶é—´æ®µåˆ†ä¸º {target_groups} ä¸ªå¤§ç»„è¿›è¡Œæ ‡è®°")
        print(f"   æ¯ç»„åŒ…å«çº¦ {group_size} ä¸ªæ—¶é—´æ®µ")

        # å­˜å‚¨æ‰€æœ‰æ•°æ®ç‚¹
        all_data_points = []
        group_info = []  # å­˜å‚¨å¤§æ—¶é—´æ®µä¿¡æ¯

        # å…ˆè®¡ç®—æ¯ä¸ªå¤§æ—¶é—´æ®µçš„ä¿¡æ¯
        for group_idx in range(target_groups):
            start_idx = group_idx * group_size
            if group_idx == target_groups - 1:
                end_idx = len(efficiency_data_sorted)
            else:
                end_idx = (group_idx + 1) * group_size

            group_data = efficiency_data_sorted.iloc[start_idx:end_idx]

            if len(group_data) > 0:
                # æ‰¾åˆ°æ—¶é—´æ®µå¤„äºæœ€ä¸­é—´ä½ç½®çš„æ•°æ®ç‚¹
                middle_relative_idx = len(group_data) // 2
                middle_absolute_idx = start_idx + middle_relative_idx
                middle_point = efficiency_data_sorted.iloc[middle_relative_idx]

                # è·å–æ—¶é—´èŒƒå›´
                first_window = group_data.iloc[0]
                last_window = group_data.iloc[-1]

                start_time_str = first_window['window_start'].strftime('%m-%d')
                end_time_str = last_window['window_end'].strftime('%m-%d')

                if start_time_str == end_time_str:
                    time_display = start_time_str
                else:
                    time_display = f"{start_time_str}~{end_time_str}"

                group_info.append({
                    'group_idx': group_idx,
                    'start_idx': start_idx,
                    'end_idx': end_idx,
                    'middle_data_idx': middle_absolute_idx,
                    'time_display': time_display,
                    'middle_efficiency': middle_point['efficiency']
                })

        # ä¸ºæ‰€æœ‰æ•°æ®ç‚¹æ·»åŠ ä¿¡æ¯
        for i, row in efficiency_data_sorted.iterrows():
            # åˆ¤æ–­è¿™ä¸ªç‚¹å±äºå“ªä¸ªå¤§æ—¶é—´æ®µ
            group_idx = min(i // group_size, target_groups - 1)
            group = group_info[group_idx] if group_idx < len(group_info) else None

            # åˆ¤æ–­æ˜¯å¦æ˜¯å¤§æ—¶é—´æ®µçš„ä¸­é—´ä½ç½®ç‚¹
            is_median_point = group and i == group['middle_data_idx']

            # æ ¼å¼åŒ–å•ä¸ªæ—¶é—´æ®µçš„æ—¶é—´æ˜¾ç¤º
            individual_start = row['window_start'].strftime('%m-%d %H:%M')
            individual_end = row['window_end'].strftime('%H:%M')
            individual_time_display = f"{individual_start}-{individual_end}"

            point_data = {
                'segment': i + 1,  # åŸå§‹åºå·
                'group_idx': group_idx + 1,  # æ‰€å±å¤§æ—¶é—´æ®µ
                'time_start': row['time'],
                'time_end': row['time'],
                'time_start_str': individual_start,
                'time_end_str': individual_end,
                'time_display': individual_time_display,
                'group_time_display': group['time_display'] if group else '',
                'efficiency': row['efficiency'],
                'inlet_conc': row.get('inlet_conc', 0),
                'outlet_conc': row.get('outlet_conc', 0),
                'data_count': row.get('data_count', 1),
                'is_median_point': is_median_point,
                'window_start': row['window_start'],
                'window_end': row['window_end']
            }

            all_data_points.append(point_data)

        print(f"   å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(all_data_points)} ä¸ªæ•°æ®ç‚¹")
        print(f"   å…¶ä¸­ {sum(1 for p in all_data_points if p['is_median_point'])} ä¸ªä¸ºå¤§æ—¶é—´æ®µä¸­ä½å€¼ç‚¹")

        return all_data_points

    def _create_final_visualization(self, segment_data: List[Dict], method_name: str) -> plt.Figure:
        """åˆ›å»ºæœ€ç»ˆçš„å¯è§†åŒ–å›¾åƒ - ä¸åŸºäºæœ€ç»ˆç‰ˆç®—æ³•çš„å¯è§†åŒ–ä¿æŒä¸€è‡´"""
        if not segment_data:
            raise ValueError("æ²¡æœ‰æ—¶é—´æ®µæ•°æ®å¯ç”¨äºå¯è§†åŒ–")

        # åˆ›å»ºå›¾åƒï¼Œå¯ç”¨äº¤äº’åŠŸèƒ½
        fig, ax = plt.subplots(1, 1, figsize=(18, 12))

        # æå–æ•°æ®
        efficiencies = [d['efficiency'] for d in segment_data]
        x_positions = list(range(1, len(segment_data) + 1))

        # åˆ†ç¦»ä¸­ä½å€¼ç‚¹å’Œæ™®é€šç‚¹ï¼Œè¿‡æ»¤æ‰æ•ˆç‡ä¸º0çš„ç‚¹
        median_points = [(i+1, d['efficiency']) for i, d in enumerate(segment_data)
                        if d['is_median_point'] and d['efficiency'] > 0]
        normal_points = [(i+1, d['efficiency']) for i, d in enumerate(segment_data)
                        if not d['is_median_point'] and d['efficiency'] > 0]

        # ç»˜åˆ¶æ‰€æœ‰æ•°æ®ç‚¹çš„è¿çº¿ï¼ˆæ¨¡ç³Šå¤„ç†ï¼‰
        ax.plot(x_positions, efficiencies, 'b-', linewidth=1.5, alpha=0.5, label='æ•ˆç‡æ›²çº¿', zorder=2)

        # ç»˜åˆ¶æ™®é€šæ•°æ®ç‚¹ï¼ˆæ¨¡ç³Šå¤„ç†ï¼Œè¾ƒå°ï¼Œç”¨äºé¼ æ ‡æ‚¬åœï¼‰
        if normal_points:
            normal_x, normal_y = zip(*normal_points)
            scatter_normal = ax.scatter(normal_x, normal_y, color='lightblue', s=60, zorder=3,
                          label='æ™®é€šæ•°æ®ç‚¹', edgecolors='blue', linewidth=0.5, alpha=0.4)

        # ç»˜åˆ¶ä¸­é—´ä½ç½®ç‚¹ï¼ˆæ¸…æ™°æ˜¾ç¤ºï¼Œè¾ƒå¤§ï¼Œçº¢è‰²ï¼‰
        if median_points:
            median_x, median_y = zip(*median_points)
            scatter_median = ax.scatter(median_x, median_y, color='red', s=180, zorder=6,
                          label='å¤§æ—¶é—´æ®µä¸­é—´ç‚¹', edgecolors='darkred', linewidth=2, alpha=0.9)

        # åªä¸ºå¤§æ—¶é—´æ®µä¸­é—´ä½ç½®ç‚¹ä¸”æ•ˆç‡å¤§äº0çš„ç‚¹æ·»åŠ é»„è‰²æ ‡ç­¾
        for i, data in enumerate(segment_data):
            if data['is_median_point'] and data['efficiency'] > 0:
                x_pos = i + 1
                efficiency = data['efficiency']

                # åŠ¨æ€è°ƒæ•´æ ‡ç­¾ä½ç½®ï¼Œé¿å…ä¸å›¾ä¾‹é‡å 
                if x_pos < len(segment_data) * 0.2:  # å·¦ä¾§20%åŒºåŸŸ
                    offset_y = 25  # å‘ä¸Šåç§»æ›´å¤š
                    offset_x = 15  # å‘å³åç§»
                else:
                    offset_y = 20
                    offset_x = 0

                # é»„è‰²æ ‡ç­¾æ˜¾ç¤ºæ•ˆç‡
                ax.annotate(f'{efficiency:.1f}%',
                           xy=(x_pos, efficiency),
                           xytext=(offset_x, offset_y),
                           textcoords='offset points',
                           fontsize=11,
                           ha='center',
                           va='bottom',
                           fontweight='bold',
                           zorder=10,  # ç¡®ä¿æ ‡ç­¾åœ¨æœ€ä¸Šå±‚
                           bbox=dict(boxstyle='round,pad=0.3',
                                   facecolor='yellow',
                                   alpha=0.95,
                                   edgecolor='orange',
                                   linewidth=1.5),
                           arrowprops=dict(arrowstyle='->',
                                         connectionstyle='arc3,rad=0',
                                         color='orange',
                                         linewidth=1.5,
                                         alpha=0.8))

        # æ·»åŠ äº¤äº’å¼tooltipåŠŸèƒ½
        def on_hover(event):
            if event.inaxes == ax:
                # æ‰¾åˆ°æœ€è¿‘çš„æ•°æ®ç‚¹
                if event.xdata is not None and event.ydata is not None:
                    distances = [(abs(event.xdata - (i+1)) + abs(event.ydata - d['efficiency']))
                               for i, d in enumerate(segment_data)]
                    min_idx = distances.index(min(distances))

                    # å¦‚æœè·ç¦»è¶³å¤Ÿè¿‘ä¸”ä¸æ˜¯ä¸­ä½å€¼ç‚¹ä¸”æ•ˆç‡å¤§äº0ï¼Œæ˜¾ç¤ºtooltip
                    if (distances[min_idx] < 2 and
                        not segment_data[min_idx]['is_median_point'] and
                        segment_data[min_idx]['efficiency'] > 0):
                        data = segment_data[min_idx]
                        tooltip_text = (f"æ—¶é—´æ®µ: {data['time_display']}\n"
                                      f"å¤„ç†æ•ˆç‡: {data['efficiency']:.1f}%\n"
                                      f"æ‰€å±å¤§ç»„: ç¬¬{data['group_idx']}ç»„")

                        # æ¸…é™¤ä¹‹å‰çš„tooltip
                        for txt in ax.texts:
                            if hasattr(txt, 'is_tooltip'):
                                txt.remove()

                        # åŠ¨æ€è°ƒæ•´tooltipä½ç½®ï¼Œé¿å…é®æŒ¡
                        tooltip_x_offset = 25 if min_idx < len(segment_data) * 0.8 else -80
                        tooltip_y_offset = 25 if data['efficiency'] < max(efficiencies) * 0.8 else -60

                        # æ·»åŠ æ–°çš„tooltip
                        tooltip = ax.annotate(tooltip_text,
                                            xy=(min_idx + 1, data['efficiency']),
                                            xytext=(tooltip_x_offset, tooltip_y_offset),
                                            textcoords='offset points',
                                            fontsize=9,
                                            ha='left' if tooltip_x_offset > 0 else 'right',
                                            va='bottom' if tooltip_y_offset > 0 else 'top',
                                            zorder=15,  # æœ€é«˜å±‚çº§
                                            bbox=dict(boxstyle='round,pad=0.4',
                                                    facecolor='lightgray',
                                                    alpha=0.95,
                                                    edgecolor='darkgray',
                                                    linewidth=1),
                                            arrowprops=dict(arrowstyle='->',
                                                          color='darkgray',
                                                          alpha=0.8,
                                                          linewidth=1))
                        tooltip.is_tooltip = True
                        fig.canvas.draw_idle()

        # è¿æ¥é¼ æ ‡ç§»åŠ¨äº‹ä»¶
        fig.canvas.mpl_connect('motion_notify_event', on_hover)

        # è®¾ç½®åæ ‡è½´
        ax.set_xlabel('æ—¶é—´æ®µåºå· / å¤§æ—¶é—´æ®µç»„', fontsize=16, fontweight='bold')
        ax.set_ylabel('å¤„ç†æ•ˆç‡ (%)', fontsize=16, fontweight='bold')
        ax.set_title(f'æŠ½å–å¼å¸é™„æ›²çº¿ - {method_name}å®Œæ•´æ•°æ®ç‚¹åˆ†æ', fontsize=18, fontweight='bold', pad=20)

        # è®¾ç½®xè½´ - é€‚å½“ç¨€ç–æ˜¾ç¤ºåˆ»åº¦
        step = max(1, len(x_positions)//20)  # è®¡ç®—æ­¥é•¿
        sparse_ticks = x_positions[::step]  # ç¨€ç–çš„åˆ»åº¦ä½ç½®
        sparse_labels = [str(x) for x in sparse_ticks]  # å¯¹åº”çš„æ ‡ç­¾

        ax.set_xticks(sparse_ticks)
        ax.set_xticklabels(sparse_labels, fontsize=10)
        ax.set_xlim(0.5, len(segment_data) + 0.5)

        # æ·»åŠ å¤§æ—¶é—´æ®µçš„åˆ†ç»„æ ‡è¯†
        # æ‰¾åˆ°æ¯ä¸ªå¤§æ—¶é—´æ®µçš„è¾¹ç•Œå’Œä¸­å¿ƒä½ç½®
        group_boundaries = {}
        for i, data in enumerate(segment_data):
            group_idx = data['group_idx']
            if group_idx not in group_boundaries:
                group_boundaries[group_idx] = {'start': i+1, 'end': i+1, 'display': data['group_time_display']}
            else:
                group_boundaries[group_idx]['end'] = i+1

        # è®¾ç½®yè½´èŒƒå›´ï¼Œä¸ºä¸‹æ–¹æ ‡ç­¾ç•™å‡ºç©ºé—´
        if efficiencies:
            y_min = min(efficiencies) - 15
            y_max = max(efficiencies) + 10
            ax.set_ylim(y_min, y_max)

        # åœ¨xè½´ä¸‹æ–¹æ·»åŠ å¤§æ—¶é—´æ®µæ ‡ç­¾
        for group_idx, bounds in group_boundaries.items():
            center_x = (bounds['start'] + bounds['end']) / 2
            ax.text(center_x, y_min + 5,  # ä½¿ç”¨å›ºå®šçš„yä½ç½®
                   f"ç»„{group_idx}\n{bounds['display']}",
                   ha='center', va='center', fontsize=9, fontweight='bold',
                   bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))

            # æ·»åŠ åˆ†ç»„åˆ†éš”çº¿
            if bounds['end'] < len(segment_data):
                ax.axvline(x=bounds['end'] + 0.5, color='gray', linestyle='--', alpha=0.5, linewidth=1)

        # ç¾åŒ–
        ax.tick_params(axis='both', which='major', labelsize=12)
        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.8)

        # å°†å›¾ä¾‹ç§»åˆ°å·¦ä¸Šè§’ï¼Œè®¾ç½®é€æ˜èƒŒæ™¯é¿å…é®æŒ¡
        ax.legend(fontsize=12, loc='upper left', framealpha=0.8,
                 fancybox=True, shadow=True, ncol=1,
                 bbox_to_anchor=(0.02, 0.98))

        # è®¾ç½®è¾¹æ¡†
        for spine in ax.spines.values():
            spine.set_linewidth(1.5)

        plt.tight_layout()
        return fig

    def analyze_warning_system(self):
        """åˆ†æé¢„è­¦ç³»ç»Ÿ"""
        # é€‰æ‹©æœ€ä½³çš„æ•ˆç‡æ•°æ®è¿›è¡Œé¢„è­¦åˆ†æ
        efficiency_data = None
        method_name = ""

        if self.efficiency_data_ks is not None and len(self.efficiency_data_ks) > 0:
            efficiency_data = self.efficiency_data_ks
            method_name = "K-Sæ£€éªŒ"
        elif self.efficiency_data_boxplot is not None and len(self.efficiency_data_boxplot) > 0:
            efficiency_data = self.efficiency_data_boxplot
            method_name = "ç®±å‹å›¾"

        if efficiency_data is None or len(efficiency_data) == 0:
            print("æ— æœ‰æ•ˆæ•ˆç‡æ•°æ®ï¼Œè·³è¿‡é¢„è­¦åˆ†æ")
            return

        print(f"ä½¿ç”¨{method_name}æ¸…æ´—åçš„æ•°æ®è¿›è¡Œé¢„è­¦åˆ†æ")
        print(f"æ•ˆç‡æ•°æ®ç‚¹æ•°: {len(efficiency_data)}")

        # å‡†å¤‡æ•°æ®
        time_data = efficiency_data['time'].values
        efficiency_values = efficiency_data['efficiency'].values

        # æ‹ŸåˆLogisticæ¨¡å‹
        if self.warning_model.fit_model(time_data, efficiency_values):
            print("Logisticæ¨¡å‹æ‹ŸåˆæˆåŠŸ")

            # ç”Ÿæˆé¢„è­¦äº‹ä»¶
            self.warning_events = []
            for _, row in efficiency_data.iterrows():
                event = self.warning_model.generate_warning_event(row['time'], row['efficiency'])
                if event is not None:
                    self.warning_events.append(event)

            print(f"ç”Ÿæˆé¢„è­¦äº‹ä»¶: {len(self.warning_events)} ä¸ª")

            # æ˜¾ç¤ºé¢„è­¦æ‘˜è¦
            self._display_warning_summary()

        else:
            print("Logisticæ¨¡å‹æ‹Ÿåˆå¤±è´¥ï¼Œæ— æ³•è¿›è¡Œé¢„è­¦åˆ†æ")

    def _display_warning_summary(self):
        """æ˜¾ç¤ºé¢„è­¦æ‘˜è¦"""
        if not self.warning_events:
            print("âœ… å½“å‰æ— é¢„è­¦äº‹ä»¶ï¼Œè®¾å¤‡è¿è¡Œæ­£å¸¸")
            return

        print(f"\nâš ï¸  æ£€æµ‹åˆ° {len(self.warning_events)} ä¸ªé¢„è­¦äº‹ä»¶:")

        # æŒ‰é¢„è­¦ç­‰çº§åˆ†ç±»
        warning_counts = {}
        latest_event = None

        for event in self.warning_events:
            level = event.warning_level.value
            warning_counts[level] = warning_counts.get(level, 0) + 1

            if latest_event is None or event.timestamp > latest_event.timestamp:
                latest_event = event

        # æ˜¾ç¤ºç»Ÿè®¡
        for level, count in warning_counts.items():
            print(f"  {level}: {count} æ¬¡")

        # æ˜¾ç¤ºæœ€æ–°é¢„è­¦
        if latest_event:
            print(f"\nğŸš¨ æœ€æ–°é¢„è­¦çŠ¶æ€: {latest_event.warning_level.value}")
            print(f"   æ—¶é—´: {latest_event.timestamp:.1f}s")
            print(f"   ç©¿é€ç‡: {latest_event.breakthrough_ratio:.1f}%")
            print(f"   å¸é™„æ•ˆç‡: {latest_event.efficiency:.1f}%")
            print(f"   åŸå› : {latest_event.reason}")
            print(f"   å»ºè®®: {latest_event.recommendation}")

            if latest_event.predicted_saturation_time:
                print(f"   é¢„æµ‹é¥±å’Œæ—¶é—´: {latest_event.predicted_saturation_time:.1f}s")

        # æ˜¾ç¤ºå…³é”®æ—¶é—´ç‚¹
        if self.warning_model.fitted:
            print(f"\nğŸ“Š å…³é”®æ—¶é—´ç‚¹é¢„æµ‹:")
            if self.warning_model.breakthrough_start_time:
                print(f"   ç©¿é€èµ·å§‹æ—¶é—´: {self.warning_model.breakthrough_start_time:.1f}s")
            if self.warning_model.warning_time:
                print(f"   é¢„è­¦æ—¶é—´: {self.warning_model.warning_time:.1f}s")
            if self.warning_model.predicted_saturation_time:
                print(f"   é¢„æµ‹é¥±å’Œæ—¶é—´: {self.warning_model.predicted_saturation_time:.1f}s")

    def create_warning_visualization(self, efficiency_data: pd.DataFrame) -> plt.Figure:
        """åˆ›å»ºåŒ…å«é¢„è­¦ä¿¡æ¯çš„å¯è§†åŒ–å›¾è¡¨"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('æ´»æ€§ç‚­å¸é™„æ•ˆç‡åˆ†æä¸é¢„è­¦ç³»ç»Ÿ', fontsize=16, fontweight='bold')

        # 1. å¸é™„æ•ˆç‡è¶‹åŠ¿å›¾
        ax1 = axes[0, 0]
        ax1.plot(efficiency_data['time'], efficiency_data['efficiency'],
                'b-', linewidth=2, label='å¸é™„æ•ˆç‡', alpha=0.8)

        # æ·»åŠ æ•ˆç‡è­¦æˆ’çº¿
        ax1.axhline(y=80, color='orange', linestyle='--', alpha=0.7, label='æ•ˆç‡è­¦æˆ’çº¿(80%)')
        ax1.axhline(y=60, color='red', linestyle='--', alpha=0.7, label='æ•ˆç‡å±é™©çº¿(60%)')

        # æ ‡è®°é¢„è­¦äº‹ä»¶
        if self.warning_events:
            warning_times = [event.timestamp for event in self.warning_events]
            warning_efficiencies = [event.efficiency for event in self.warning_events]
            warning_colors = []

            for event in self.warning_events:
                if event.warning_level == WarningLevel.YELLOW:
                    warning_colors.append('yellow')
                elif event.warning_level == WarningLevel.ORANGE:
                    warning_colors.append('orange')
                elif event.warning_level == WarningLevel.RED:
                    warning_colors.append('red')
                else:
                    warning_colors.append('green')

            ax1.scatter(warning_times, warning_efficiencies, c=warning_colors,
                       s=100, alpha=0.8, edgecolors='black', linewidth=1,
                       label='é¢„è­¦äº‹ä»¶', zorder=5)

        ax1.set_xlabel('æ—¶é—´ (s)')
        ax1.set_ylabel('å¸é™„æ•ˆç‡ (%)')
        ax1.set_title('å¸é™„æ•ˆç‡å˜åŒ–è¶‹åŠ¿')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # 2. ç©¿é€ç‡è¶‹åŠ¿å›¾
        ax2 = axes[0, 1]
        breakthrough_ratios = (100 - efficiency_data['efficiency']) / 100 * 100
        ax2.plot(efficiency_data['time'], breakthrough_ratios,
                'r-', linewidth=2, label='å®é™…ç©¿é€ç‡', alpha=0.8)

        # æ·»åŠ é¢„è­¦é˜ˆå€¼çº¿
        ax2.axhline(y=5, color='green', linestyle='--', alpha=0.7, label='ç©¿é€èµ·å§‹ç‚¹(5%)')
        ax2.axhline(y=80, color='orange', linestyle='--', alpha=0.7, label='é¢„è­¦é˜ˆå€¼(80%)')
        ax2.axhline(y=95, color='red', linestyle='--', alpha=0.7, label='é¥±å’Œé˜ˆå€¼(95%)')

        # å¦‚æœæœ‰Logisticæ¨¡å‹æ‹Ÿåˆç»“æœï¼Œç»˜åˆ¶æ‹Ÿåˆæ›²çº¿å’Œé¢„æµ‹
        if self.warning_model.fitted:
            time_smooth = np.linspace(efficiency_data['time'].min(),
                                    efficiency_data['time'].max() * 1.2, 300)
            bt_smooth = self.warning_model.predict_breakthrough(time_smooth) * 100
            ax2.plot(time_smooth, bt_smooth, 'g--', linewidth=2,
                    alpha=0.8, label='Logisticé¢„æµ‹æ›²çº¿')

            # æ ‡è®°å…³é”®æ—¶é—´ç‚¹
            if self.warning_model.breakthrough_start_time:
                ax2.axvline(x=self.warning_model.breakthrough_start_time,
                           color='green', linestyle=':', alpha=0.8, label='ç©¿é€èµ·å§‹æ—¶é—´')
            if self.warning_model.warning_time:
                ax2.axvline(x=self.warning_model.warning_time,
                           color='orange', linestyle=':', alpha=0.8, label='é¢„è­¦æ—¶é—´')
            if self.warning_model.predicted_saturation_time:
                ax2.axvline(x=self.warning_model.predicted_saturation_time,
                           color='red', linestyle=':', alpha=0.8, label='é¢„æµ‹é¥±å’Œæ—¶é—´')

        ax2.set_xlabel('æ—¶é—´ (s)')
        ax2.set_ylabel('ç©¿é€ç‡ (%)')
        ax2.set_title('ç©¿é€ç‡å˜åŒ–è¶‹åŠ¿ä¸é¢„æµ‹')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # 3. é¢„è­¦çŠ¶æ€åˆ†å¸ƒ
        ax3 = axes[1, 0]
        if self.warning_events:
            warning_counts = {}
            for event in self.warning_events:
                level = event.warning_level.value
                warning_counts[level] = warning_counts.get(level, 0) + 1

            colors = {'ç»¿è‰²': 'green', 'é»„è‰²': 'yellow', 'æ©™è‰²': 'orange', 'çº¢è‰²': 'red'}
            pie_colors = [colors.get(level, 'gray') for level in warning_counts.keys()]

            ax3.pie(warning_counts.values(), labels=warning_counts.keys(),
                   colors=pie_colors, autopct='%1.1f%%', startangle=90)
            ax3.set_title('é¢„è­¦ç­‰çº§åˆ†å¸ƒ')
        else:
            ax3.text(0.5, 0.5, 'æš‚æ— é¢„è­¦äº‹ä»¶\nè®¾å¤‡è¿è¡Œæ­£å¸¸', ha='center', va='center',
                    transform=ax3.transAxes, fontsize=14,
                    bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))
            ax3.set_title('é¢„è­¦çŠ¶æ€')

        # 4. é¢„è­¦æ—¶é—´çº¿
        ax4 = axes[1, 1]
        if self.warning_events:
            sorted_events = sorted(self.warning_events, key=lambda x: x.timestamp)

            times = [event.timestamp for event in sorted_events]
            levels = [event.warning_level.value for event in sorted_events]

            level_colors = {'ç»¿è‰²': 'green', 'é»„è‰²': 'yellow', 'æ©™è‰²': 'orange', 'çº¢è‰²': 'red'}
            colors = [level_colors.get(level, 'gray') for level in levels]

            ax4.scatter(times, range(len(times)), c=colors, s=100, alpha=0.7)

            ax4.set_yticks(range(len(times)))
            ax4.set_yticklabels([f"äº‹ä»¶{i+1}" for i in range(len(times))])

            # æ·»åŠ é¢„è­¦ç­‰çº§æ ‡ç­¾
            for i, (time, level) in enumerate(zip(times, levels)):
                ax4.annotate(level, (time, i), xytext=(5, 0),
                           textcoords='offset points', va='center', fontsize=9)
        else:
            ax4.text(0.5, 0.5, 'æš‚æ— é¢„è­¦äº‹ä»¶', ha='center', va='center',
                    transform=ax4.transAxes, fontsize=14)

        ax4.set_xlabel('æ—¶é—´ (s)')
        ax4.set_title('é¢„è­¦äº‹ä»¶æ—¶é—´çº¿')
        ax4.grid(True, alpha=0.3)

        plt.tight_layout()
        return fig

    def process_and_visualize(self):
        """å®Œæ•´çš„æ•°æ®å¤„ç†å’Œå¯è§†åŒ–æµç¨‹"""
        print("=== æŠ½å–å¼å¸é™„æ›²çº¿å®Œæ•´æ•°æ®å¤„ç†ä¸å¯è§†åŒ– ===")
        print("="*60)

        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        cleaned_data_dir = "å¯è§†åŒ–é¡¹ç›®/æ¸…æ´—åæ•°æ®"
        visualization_dir = "å¯è§†åŒ–é¡¹ç›®/å¯è§†åŒ–å›¾åƒ"

        os.makedirs(cleaned_data_dir, exist_ok=True)
        os.makedirs(visualization_dir, exist_ok=True)

        print(f"æ¸…æ´—åæ•°æ®å°†ä¿å­˜åˆ°: {cleaned_data_dir}")
        print(f"å¯è§†åŒ–å›¾åƒå°†ä¿å­˜åˆ°: {visualization_dir}")

        # 1. åŠ è½½æ•°æ®
        if not self.load_data():
            return

        # 2. åŸºç¡€æ•°æ®æ¸…æ´—
        basic_cleaned = self.basic_data_cleaning(self.raw_data)
        if len(basic_cleaned) == 0:
            print("åŸºç¡€æ¸…æ´—åæ— æ•°æ®ï¼Œç¨‹åºç»“æŸ")
            return

        # 3. K-Sæ£€éªŒæ¸…æ´—
        print("\n" + "="*40)
        print("å¼€å§‹K-Sæ£€éªŒæ•°æ®æ¸…æ´—")
        self.cleaned_data_ks = self.ks_test_cleaning(basic_cleaned)

        # 4. ç®±å‹å›¾æ¸…æ´—
        print("\n" + "="*40)
        print("å¼€å§‹ç®±å‹å›¾æ•°æ®æ¸…æ´—")
        self.cleaned_data_boxplot = self.boxplot_cleaning(basic_cleaned)

        # 5. è®¡ç®—æ•ˆç‡æ•°æ®
        if len(self.cleaned_data_ks) > 0:
            self.efficiency_data_ks = self.calculate_efficiency_data(self.cleaned_data_ks, "K-Sæ£€éªŒ")

        if len(self.cleaned_data_boxplot) > 0:
            self.efficiency_data_boxplot = self.calculate_efficiency_data(self.cleaned_data_boxplot, "ç®±å‹å›¾")

        # 6. é¢„è­¦åˆ†æ
        print("\n" + "="*40)
        print("å¼€å§‹é¢„è­¦åˆ†æ")
        self.analyze_warning_system()

        # 7. åˆ›å»ºå¯è§†åŒ–
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # K-Sæ£€éªŒå¯è§†åŒ–
        if self.efficiency_data_ks is not None and len(self.efficiency_data_ks) > 0:
            print("\n" + "="*40)
            print("åˆ›å»ºK-Sæ£€éªŒå¯è§†åŒ–")
            ks_segments = self._create_time_segments(self.efficiency_data_ks)
            if ks_segments:
                fig_ks = self._create_final_visualization(ks_segments, "K-Sæ£€éªŒæ¸…æ´—")
                filename_ks = os.path.join(visualization_dir, f"{self.base_filename}_KSæ£€éªŒæ¸…æ´—_{timestamp}.png")
                fig_ks.savefig(filename_ks, dpi=300, bbox_inches='tight')
                print(f"K-Sæ£€éªŒå¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜: {filename_ks}")
                plt.show()

        # ç®±å‹å›¾å¯è§†åŒ–
        if self.efficiency_data_boxplot is not None and len(self.efficiency_data_boxplot) > 0:
            print("\n" + "="*40)
            print("åˆ›å»ºç®±å‹å›¾å¯è§†åŒ–")
            box_segments = self._create_time_segments(self.efficiency_data_boxplot)
            if box_segments:
                fig_box = self._create_final_visualization(box_segments, "ç®±å‹å›¾æ¸…æ´—")
                filename_box = os.path.join(visualization_dir, f"{self.base_filename}_ç®±å‹å›¾æ¸…æ´—_{timestamp}.png")
                fig_box.savefig(filename_box, dpi=300, bbox_inches='tight')
                print(f"ç®±å‹å›¾å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜: {filename_box}")
                plt.show()

        # é¢„è­¦ç³»ç»Ÿå¯è§†åŒ–
        if self.warning_events or self.warning_model.fitted:
            print("\n" + "="*40)
            print("åˆ›å»ºé¢„è­¦ç³»ç»Ÿå¯è§†åŒ–")

            # é€‰æ‹©æœ€ä½³çš„æ•ˆç‡æ•°æ®
            efficiency_data = None
            if self.efficiency_data_ks is not None and len(self.efficiency_data_ks) > 0:
                efficiency_data = self.efficiency_data_ks
            elif self.efficiency_data_boxplot is not None and len(self.efficiency_data_boxplot) > 0:
                efficiency_data = self.efficiency_data_boxplot

            if efficiency_data is not None:
                fig_warning = self.create_warning_visualization(efficiency_data)
                filename_warning = os.path.join(visualization_dir, f"{self.base_filename}_é¢„è­¦ç³»ç»Ÿ_{timestamp}.png")
                fig_warning.savefig(filename_warning, dpi=300, bbox_inches='tight')
                print(f"é¢„è­¦ç³»ç»Ÿå¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜: {filename_warning}")
                plt.show()

        # 8. ä¿å­˜æ¸…æ´—åçš„æ•°æ®
        if len(self.cleaned_data_ks) > 0:
            ks_filename = os.path.join(cleaned_data_dir, f"{self.base_filename}_KSæ£€éªŒæ¸…æ´—_{timestamp}.csv")
            self.cleaned_data_ks.to_csv(ks_filename, index=False, encoding='utf-8-sig')
            print(f"K-Sæ£€éªŒæ¸…æ´—æ•°æ®å·²ä¿å­˜: {ks_filename}")

        if len(self.cleaned_data_boxplot) > 0:
            box_filename = os.path.join(cleaned_data_dir, f"{self.base_filename}_ç®±å‹å›¾æ¸…æ´—_{timestamp}.csv")
            self.cleaned_data_boxplot.to_csv(box_filename, index=False, encoding='utf-8-sig')
            print(f"ç®±å‹å›¾æ¸…æ´—æ•°æ®å·²ä¿å­˜: {box_filename}")

        # 9. ä¿å­˜é¢„è­¦æŠ¥å‘Š
        if self.warning_events or self.warning_model.fitted:
            self._save_warning_report(cleaned_data_dir, timestamp)

        print("\n" + "="*60)
        print("æ•°æ®å¤„ç†ã€å¯è§†åŒ–ä¸é¢„è­¦åˆ†æå®Œæˆï¼")

        # æ˜¾ç¤ºæœ€ç»ˆé¢„è­¦æ‘˜è¦
        if self.warning_events:
            print("\nğŸš¨ æœ€ç»ˆé¢„è­¦æ‘˜è¦:")
            latest_event = max(self.warning_events, key=lambda x: x.timestamp)
            print(f"   å½“å‰é¢„è­¦çŠ¶æ€: {latest_event.warning_level.value}")
            print(f"   æ€»é¢„è­¦äº‹ä»¶æ•°: {len(self.warning_events)}")
            if self.warning_model.predicted_saturation_time:
                print(f"   é¢„æµ‹é¥±å’Œæ—¶é—´: {self.warning_model.predicted_saturation_time:.1f}s")
        else:
            print("\nâœ… è®¾å¤‡è¿è¡Œæ­£å¸¸ï¼Œæ— é¢„è­¦äº‹ä»¶")

    def _save_warning_report(self, output_dir: str, timestamp: str):
        """ä¿å­˜é¢„è­¦æŠ¥å‘Š"""
        report_filename = os.path.join(output_dir, f"{self.base_filename}_é¢„è­¦æŠ¥å‘Š_{timestamp}.txt")

        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write("æ´»æ€§ç‚­æ›´æ¢é¢„è­¦æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")

            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ•°æ®æ–‡ä»¶: {self.data_file}\n\n")

            # Logisticæ¨¡å‹ä¿¡æ¯
            if self.warning_model.fitted:
                f.write("Logisticæ¨¡å‹æ‹Ÿåˆç»“æœ:\n")
                f.write(f"  å‚æ•°: A={self.warning_model.params[0]:.3f}, k={self.warning_model.params[1]:.6f}, t0={self.warning_model.params[2]:.1f}\n")

                if self.warning_model.breakthrough_start_time:
                    f.write(f"  ç©¿é€èµ·å§‹æ—¶é—´: {self.warning_model.breakthrough_start_time:.1f}s\n")
                if self.warning_model.warning_time:
                    f.write(f"  é¢„è­¦æ—¶é—´: {self.warning_model.warning_time:.1f}s\n")
                if self.warning_model.predicted_saturation_time:
                    f.write(f"  é¢„æµ‹é¥±å’Œæ—¶é—´: {self.warning_model.predicted_saturation_time:.1f}s\n")
                f.write("\n")
            else:
                f.write("Logisticæ¨¡å‹æ‹Ÿåˆå¤±è´¥\n\n")

            # é¢„è­¦äº‹ä»¶
            if self.warning_events:
                f.write(f"é¢„è­¦äº‹ä»¶æ€»æ•°: {len(self.warning_events)}\n\n")

                # æŒ‰é¢„è­¦ç­‰çº§åˆ†ç±»ç»Ÿè®¡
                warning_counts = {}
                for event in self.warning_events:
                    level = event.warning_level.value
                    warning_counts[level] = warning_counts.get(level, 0) + 1

                f.write("é¢„è­¦ç­‰çº§ç»Ÿè®¡:\n")
                for level, count in warning_counts.items():
                    f.write(f"  {level}: {count} æ¬¡\n")
                f.write("\n")

                # è¯¦ç»†é¢„è­¦äº‹ä»¶
                f.write("è¯¦ç»†é¢„è­¦äº‹ä»¶:\n")
                f.write("-" * 40 + "\n")

                for i, event in enumerate(self.warning_events, 1):
                    f.write(f"\näº‹ä»¶ {i}:\n")
                    f.write(f"  æ—¶é—´: {event.timestamp:.1f}s\n")
                    f.write(f"  é¢„è­¦ç­‰çº§: {event.warning_level.value}\n")
                    f.write(f"  ç©¿é€ç‡: {event.breakthrough_ratio:.1f}%\n")
                    f.write(f"  å¸é™„æ•ˆç‡: {event.efficiency:.1f}%\n")
                    f.write(f"  åŸå› : {event.reason}\n")
                    f.write(f"  å»ºè®®: {event.recommendation}\n")

                # æœ€æ–°é¢„è­¦çŠ¶æ€
                latest_event = max(self.warning_events, key=lambda x: x.timestamp)
                f.write(f"\nå½“å‰é¢„è­¦çŠ¶æ€: {latest_event.warning_level.value}\n")
                f.write(f"æœ€æ–°é¢„è­¦æ—¶é—´: {latest_event.timestamp:.1f}s\n")

            else:
                f.write("âœ… æ— é¢„è­¦äº‹ä»¶ï¼Œè®¾å¤‡è¿è¡Œæ­£å¸¸\n")

            f.write("\n" + "=" * 50 + "\n")

        print(f"é¢„è­¦æŠ¥å‘Šå·²ä¿å­˜: {report_filename}")


def main():
    """ä¸»å‡½æ•°"""
    print("æŠ½å–å¼å¸é™„æ›²çº¿å®Œæ•´æ•°æ®å¤„ç†ä¸å¯è§†åŒ–ç®—æ³•")
    print("æ”¯æŒCSVã€XLSXã€XLSæ ¼å¼æ–‡ä»¶ï¼Œå®ç°ä»æ•°æ®æ¸…æ´—åˆ°å¯è§†åŒ–çš„å…¨æµç¨‹")
    print("="*60)

    # æ•°æ®æ–‡ä»¶è·¯å¾„ - æ”¯æŒå¤šç§æ ¼å¼
    data_file = "å¯è§†åŒ–é¡¹ç›®/7.24.csv"  # å¯ä»¥æ˜¯ .csv, .xlsx, .xls æ ¼å¼

    print(f"å½“å‰å¤„ç†æ–‡ä»¶: {data_file}")
    print("æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: CSV (.csv), Excel (.xlsx, .xls)")
    print("="*60)

    # åˆ›å»ºå¤„ç†å™¨å¹¶æ‰§è¡Œå®Œæ•´æµç¨‹
    processor = AdsorptionCurveProcessor(data_file)
    processor.process_and_visualize()


if __name__ == "__main__":
    main()
